{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Thigh segmentation, Mohajer B et al., Radiology 2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Trainnig U-Net model"
      ],
      "metadata": {
        "id": "RQMnLqr6aanw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjldvkk28ane"
      },
      "source": [
        "# Installing libraries\n",
        "!pip install segmentation-models\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install keras==2.3.1\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0DZ-15m9g-E"
      },
      "source": [
        "# Importing libraries\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%env SM_FRAMEWORK=tf.keras\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y91566F-Saj"
      },
      "source": [
        "# Loading images and masks\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "img_augmented_path=\"/content/drive/MyDrive/Thigh_segmentation/Train/Images\"\n",
        "msk_augmented_path=\"/content/drive/MyDrive/Thigh_segmentation/Train/Labels\"\n",
        "\n",
        "n_classes=9 # Number of classes for segmentation\n",
        "\n",
        "# Capturing training image info as a list\n",
        "train_images = []\n",
        "\n",
        "for directory_path in sorted(glob.glob(img_augmented_path)):\n",
        "    for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.tif\"))):\n",
        "        img = cv2.imread(img_path, 1)       \n",
        "        train_images.append(img)\n",
        "       \n",
        "# Converting list to array for deep learning processing        \n",
        "train_images = np.array(train_images)\n",
        "\n",
        "# Capturing mask/label info as a list\n",
        "train_masks = [] \n",
        "for directory_path in sorted(glob.glob(msk_augmented_path)):\n",
        "    for mask_path in sorted(glob.glob(os.path.join(directory_path, \"*.tif\"))):\n",
        "        mask = cv2.imread(mask_path, 0)\n",
        "        train_masks.append(mask)\n",
        "        \n",
        "# Converting list to array   \n",
        "train_masks = np.array(train_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjw-j8Pr9CSh"
      },
      "source": [
        "# Checking the size and dimentions of arrays \n",
        "print(train_images.shape)\n",
        "print(train_masks.shape)\n",
        "# Sanity check for random images and correspounding masks\n",
        "image_x = random.randint(0, (train_images.shape)[0])\n",
        "plt.imshow(train_images[image_x])\n",
        "print (image_x)\n",
        "plt.show()\n",
        "plt.imshow((train_masks[image_x]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K53iH_FO-XtY"
      },
      "source": [
        "# Encoding labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "n, h, w = train_masks.shape\n",
        "train_masks_reshaped = train_masks.reshape(-1,1)\n",
        "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
        "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
        "print(train_masks_encoded_original_shape.shape)\n",
        "print(train_masks_reshaped_encoded.shape)\n",
        "np.unique(train_masks_encoded_original_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v16mW_bnuS6X"
      },
      "source": [
        "# Adding a dimension to masks to match images (Read in RGB)\n",
        "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3) \n",
        "\n",
        "#Create a subset of data for validation (10%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
        "print(\"Class values in the dataset are ... \", np.unique(y_train))\n",
        "\n",
        "# Reformating classes\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
        "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes)) \n",
        "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
        "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWhOKCWyuZfU"
      },
      "source": [
        "# Setting parameters\n",
        "activation='softmax'\n",
        "LR = 0.0001\n",
        "optim = tf.keras.optimizers.Adam(LR)\n",
        "total_loss = sm.losses.categorical_focal_dice_loss\n",
        "total_loss = sm.losses.bce_jaccard_loss\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h3AexC--hMe"
      },
      "source": [
        "### Model\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# preprocess input\n",
        "X_train = preprocess_input(X_train)\n",
        "X_test = preprocess_input(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTnq7p2yXtl"
      },
      "source": [
        "# Defining model\n",
        "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
        "# Compiling keras model with defined optimozer, loss and metrics\n",
        "model.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSVNmw3k7qVU"
      },
      "source": [
        "# Fitting model\n",
        "\n",
        "history=model.fit(X_train, \n",
        "          y_train_cat,\n",
        "          batch_size=10, \n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test_cat))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJjSyBi6vgn"
      },
      "source": [
        "# Saving the model\n",
        "model.save('/content/drive/MyDrive/Thigh_segmentation/thigh_segmentation.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOpjUls97AF3"
      },
      "source": [
        "#Evaluate the model accuracy\n",
        "_, acc, *is_anything_else_being_returned  = model.evaluate(X_test, y_test_cat)\n",
        "print(model.evaluate(X_test, y_test_cat))\n",
        "print(\"Accuracy is = \", (acc * 100.0), \"%\")\n",
        "model.evaluate(X_test, y_test_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DfT3801vrfu"
      },
      "source": [
        "# Plot the training and validation accuracy and loss at each epoch\n",
        "print(model.metrics_names)\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(model.metrics_names)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNKHb0v1vxk9"
      },
      "source": [
        "#Calculating total IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
        "#Using built in keras function\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LPYXnZ5x2rl"
      },
      "source": [
        "# Calculating I0U for each class on validation dataset\n",
        "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
        "class0_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[0,4] + values[0,5] + values[0,6] + values[0,7] + values[0,8] + values[1,0]+ values[2,0]+ values[3,0] + values[4,0] + values[5,0] + values[6,0] + values[7,0] + values[8,0])\n",
        "class1_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[1,4] + values[1,5] + values[1,6] + values[1,7] + values[1,8] + values[0,1]+ values[2,1]+ values[3,1] + values[4,1] + values[5,1] + values[6,1] + values[7,1] + values[8,1])\n",
        "class2_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[2,4] + values[2,5] + values[2,6] + values[2,7] + values[2,8] + values[0,2]+ values[1,2]+ values[3,2] + values[4,2] + values[5,2] + values[6,2] + values[7,2] + values[8,2])\n",
        "class3_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[3,4] + values[3,5] + values[3,6] + values[3,7] + values[3,8] + values[0,3]+ values[1,3]+ values[2,3] + values[4,3] + values[5,3] + values[6,3] + values[7,3] + values[8,3])\n",
        "class4_IoU = values[4,4]/(values[4,4] + values[4,0] + values[4,1] + values[4,2] + values[4,3] + values[4,5] + values[4,6] + values[4,7] + values[4,8] + values[0,4]+ values[1,4]+ values[2,4] + values[3,4] + values[5,4] + values[6,4] + values[7,4] + values[8,4])\n",
        "class5_IoU = values[5,5]/(values[5,5] + values[5,0] + values[5,1] + values[5,2] + values[5,3] + values[5,4] + values[5,6] + values[5,7] + values[5,8] + values[0,5]+ values[1,5]+ values[2,5] + values[3,5] + values[4,5] + values[6,5] + values[7,5] + values[8,5])\n",
        "class6_IoU = values[6,6]/(values[6,6] + values[6,0] + values[6,1] + values[6,2] + values[6,3] + values[6,4] + values[6,5] + values[6,7] + values[6,8] + values[0,6]+ values[1,6]+ values[2,6] + values[3,6] + values[4,6] + values[5,6] + values[7,6] + values[8,6])\n",
        "class7_IoU = values[7,7]/(values[7,7] + values[7,0] + values[7,1] + values[7,2] + values[7,3] + values[7,4] + values[7,5] + values[7,6] + values[7,8] + values[0,7]+ values[1,7]+ values[2,7] + values[3,7] + values[4,7] + values[5,7] + values[6,7] + values[8,7])\n",
        "class8_IoU = values[8,8]/(values[8,8] + values[8,0] + values[8,1] + values[8,2] + values[8,3] + values[8,4] + values[8,5] + values[8,6] + values[8,7] + values[0,8]+ values[1,8]+ values[2,8] + values[3,8] + values[4,8] + values[5,8] + values[6,8] + values[7,8])\n",
        "\n",
        "\n",
        "print(\"IoU for class0 (Background) is: \", class0_IoU)\n",
        "print(\"IoU for class1 (Medulla) is: \", class1_IoU)\n",
        "print(\"IoU for class2 (Bone) is: \", class2_IoU)\n",
        "print(\"IoU for class3 (SCF) is: \", class3_IoU)\n",
        "print(\"IoU for class4 (Quadriceps) is: \", class4_IoU)\n",
        "print(\"IoU for class5 (Flexors) is: \", class5_IoU)\n",
        "print(\"IoU for class6 (Adductors) is: \", class6_IoU)\n",
        "print(\"IoU for class7 (Sartorius) is: \", class7_IoU)\n",
        "print(\"IoU for class8 (IMAT) is: \", class8_IoU)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E2ZPn-Nv7mO"
      },
      "source": [
        "# Predicting on random images\n",
        "test_img_number = random.randint(0, len(X_test)-1)\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth = y_test[test_img_number]\n",
        "test_img_input = np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input))\n",
        "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(predicted_img, cmap='jet')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model on holdout test set"
      ],
      "metadata": {
        "id": "vAcUfBbJaSJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on independent data\n",
        "\n",
        "img_augmented_path=\"/content/drive/MyDrive/Thigh_segmentation/Test/Images\"\n",
        "msk_augmented_path=\"/content/drive/MyDrive/Thigh_segmentation/Test/Labels\"\n",
        "\n",
        "# Performing same formatting and preprocessing \n",
        "n_classes=9\n",
        "test_images_ext = []\n",
        "for directory_path in sorted(glob.glob(img_augmented_path)):\n",
        "    for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.tif\"))):\n",
        "        img = cv2.imread(img_path, 1)       \n",
        "        test_images_ext.append(img)\n",
        "test_images_ext = np.array(test_images_ext)\n",
        "test_masks_ext = [] \n",
        "for directory_path in sorted(glob.glob(msk_augmented_path)):\n",
        "    for mask_path in sorted(glob.glob(os.path.join(directory_path, \"*.tif\"))):\n",
        "        mask = cv2.imread(mask_path, 0)       \n",
        "        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
        "        test_masks_ext.append(mask)\n",
        "test_masks_ext = np.array(test_masks_ext)"
      ],
      "metadata": {
        "id": "eeWofySOGOy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing sanity check on loaded images and masks\n",
        "print(test_images_ext.shape)\n",
        "print(test_masks_ext.shape)\n",
        "image_x = random.randint(0, (test_images_ext.shape)[0])\n",
        "#print((test_images_ext.shape)[0])\n",
        "plt.imshow(test_images_ext[image_x])\n",
        "print (image_x)\n",
        "plt.show()\n",
        "plt.imshow((test_masks_ext[image_x]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yAr-2W66GvBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "n, h, w = test_masks_ext.shape\n",
        "test_masks_ext_reshaped = test_masks_ext.reshape(-1,1)\n",
        "test_masks_ext_reshaped_encoded = labelencoder.fit_transform(test_masks_ext_reshaped)\n",
        "test_masks_ext_encoded_original_shape = test_masks_ext_reshaped_encoded.reshape(n, h, w)\n",
        "\n",
        "print(test_masks_ext_encoded_original_shape.shape)\n",
        "print(test_masks_ext_reshaped_encoded.shape)\n",
        "np.unique(test_masks_ext_encoded_original_shape)\n",
        "X_test_ext = test_images_ext\n",
        "X_test_ext = preprocess_input(X_test_ext)\n",
        "y_test_ext = np.expand_dims(test_masks_ext_encoded_original_shape, axis=3)\n",
        "\n",
        "# Reformating test masks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "test_masks_ext_cat = to_categorical(y_test_ext, num_classes=n_classes)\n",
        "y_test_ext_cat = test_masks_ext_cat.reshape((y_test_ext.shape[0], y_test_ext.shape[1], y_test_ext.shape[2], n_classes))"
      ],
      "metadata": {
        "id": "4G2hqJsIG3I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IOU assessment\n",
        "print(X_test_ext.shape)\n",
        "y_pred_ext=model.predict(X_test_ext[:,:,:])\n",
        "y_pred_ext_argmax=np.argmax(y_pred_ext, axis=3)\n",
        "# Using built in keras function\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test_ext[:,:,:,0], y_pred_ext_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "Vwa3DIW9HFSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = 1e-12\n",
        "def get_iou( gt , pr , n_classes ):\n",
        "    class_wise = np.zeros(n_classes)\n",
        "    for cl in range(n_classes):\n",
        "        intersection = np.sum(( gt == cl )*( pr == cl ))\n",
        "        union = np.sum(np.maximum( ( gt == cl ) , ( pr == cl ) ))\n",
        "        iou = float(intersection)/( union + EPS )\n",
        "        class_wise[ cl ] = iou\n",
        "    return class_wise\n",
        "\n",
        "ious = np.array(get_iou(y_test_ext[:,:,:,0], y_pred_ext_argmax,n_classes=n_classes))\n",
        "print(ious)\n",
        "\n",
        "# Removing background in calculation of mean IOU\n",
        "print(\"Total  IoU near\"  ,  np.mean(ious[1:9] ))"
      ],
      "metadata": {
        "id": "jq21YJn4HId4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction of the masks for all other OAI subjects, using trained model"
      ],
      "metadata": {
        "id": "cBKIjiv5HRx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on independent data\n",
        "\n",
        "img_WholeOAI_path=\"/content/drive/MyDrive/Thigh_segmentation/WholeOAI/Images\"\n",
        "\n",
        "# Performing same formatting and preprocessing \n",
        "n_classes=9\n",
        "img_list_np = []\n",
        "for directory_path in sorted(glob.glob(img_WholeOAI_path)):\n",
        "    for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.tif\"))):\n",
        "        img = cv2.imread(img_path, 1)       \n",
        "        img_list_np.append(img)\n",
        "img_list_np = np.array(img_list_np)"
      ],
      "metadata": {
        "id": "IiFfK5gccVNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001\n",
        "optim = tf.keras.optimizers.Adam(LR)\n",
        "total_loss = sm.losses.categorical_focal_dice_loss\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy']\n",
        "activation='softmax'\n",
        "n_classes=9\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Thigh_segmentation/thigh_segmentation.h5', compile=False)\n",
        "model.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n",
        "\n",
        "print(img_list_np.shape)\n",
        "image_x = random.randint(0, (img_list_np.shape)[0])\n",
        "plt.imshow(img_list_np[image_x])\n",
        "print (image_x)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5eyV3lWTHXkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_predict = img_list_np\n",
        "X_predict = preprocess_input(X_predict)\n",
        "\n",
        "y_predict = model.predict(X_predict[:,:,:])\n",
        "y_predict_argmax=np.argmax(y_predict, axis=3)"
      ],
      "metadata": {
        "id": "es22sCrdHYf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on a few images\n",
        "test_img_number = random.randint(0, len(X_predict)-1)\n",
        "print(test_img_number)\n",
        "test_img = X_predict[test_img_number]\n",
        "test_img_input = np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input))\n",
        "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(predicted_img, cmap='jet')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ehJ7fi7zHcAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/Thigh_segmentation/y_predict_argmax_WholeOAI.npy',y_predict_argmax)"
      ],
      "metadata": {
        "id": "GxXZJH3MHdZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}